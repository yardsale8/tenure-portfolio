---
title: Instructional Innovation
linktitle: Instructional Innovation
toc: true
type: docs
date: "2021-01-15"
draft: false
menu:
  crit1:
    parent: Teaching Effectiveness
    weight: 1

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 1
---

The evolution of my STAT 110 Fundamentals of Statistics curriculum provides a good
illustration of my approach to blending instructional innovation and the
assessment of student learning. STAT 110 is ripe for a discussion of
instructional innovation tied to assessing student learning due to
the demand and large sections (37 versus 25), which has translated
into an opportunity to teach the course in multiple formats, be it
face-to-face in the classroom, online asynchronously over the summer, or in
an online synchronous format (due to COVID-19).

### Overview

In this section, I will provide an overview of how the course material has
evolved from a face-to-face flipped classroom to synchronous and asynchronous
online courses.

When meeting face-to-face, I implement this course using the flipped
classroom, which I discuss in more depth in the section on [criterion
4]({{<ref "/criterion4/student_centered.md">}}). I will highlight a few
additional innovations here. First, I embedded self-assessment
multiple-choice questions in an online and interactive set of course notes,
allowing students to check their understanding and review the material
outside of class. Next, I discuss the transition from a face-to-face flipped
class to an online format. Finally, I provide details about innovations
related to developing authentic assessments that translate to online formats.

## Using Embedded Self-Assessments

{{< figure src="/img/book_MC.png" title="**Figure 1.** An example of an embedded self-assessment. Students receive immediate feedback after reading each section of the book, including guidance for incorrect responses. ">}}

In two of my previous courses, STAT 110 and STAT 489, I constructed online
textbooks to supplement instruction. One of the primary advantages of
creating a web-based book is embed videos and multiple-choice problems
directly in the text. The students can then use these assessments to gauge
their understanding of the material using the immediate feedback, allowing
them to determine if they have understood the relevant material.

I use these embedded questions to prepare students for the end-of-module
assessments. Before wrapping up each module with a suite of more extensive
assessments, I give students a short quiz that consists of a random selection
of these book problems in hopes of encouraging them to go back and review the
associated material.

Here is what some of the students had to say about these embedded assessments.

> As part of student evaluations, students were prompted to comment on the online textbook. Here are some positive responses related to the embedded assessments.

> very useful. I liked the little multiple choice questions in the reading. 

> I liked this as well, with the check me quizzes and videos. Great resource for learning and exams 

> The online textbook was useful to help in giving course examples, and the questions aligned with the reading quizzes. 

> I found it useful in the way that practice questions were in there. 

> I found it useful especially the multiple choice questions embedded.

> I think the text book was very useful and i loved how they had multiple choice practice 

> I found the textbook extremely useful and liked the practice quizes/questions and videos. They helped me check my comprehension and also explained why I was wrong for some questions. a

Next, I will discuss the translation from a face-to-face flipped classroom to an online format.

## The Implementation of and Online STAT 110

{{< figure src="/img/welcome.png" title="**Figure 2.** I welcome students to the first week of STAT 110, an asynchronous online course taught during each of the 2017-2020 summer terms.">}}

During the 2017 summer term, I implemented the first online STAT 110 offering
here at WSU. Since that time, STAT 110 has been offered each summer with a
growing number of sections due to increased demand. There were several
challenges to adapting my materials to the online setting, which I will
summarize below. As is often the case, the changes made while teaching online
have also greatly benefitted my regular face-to-face courses.

**Organizational Challenges.** As discussed in the section on [criterion
3]({{<ref
"/criterion3/continuing_education.md">}}), I first took the WeTeach courses
in the spring of 2017 and then revisited (and finally completed) this course
in the summer of 2020. WeTeach has had a big impact on my online teaching,
shaping my approach to this online course, and in particular, has taught me
the importance of organization and focused communication.

We generally teach our summer offerings over eight weeks, which allowed for an easy
2-regular-weeks to 1-summer-week conversion and making it easy to map my
regular in-class activities to an online environment. The demands for better
organization forced me to rearrange the material into 8 modules, with one
module covered each week.  

I instituted a numbering scheme to improve course navigation. First,
everything in the course is identified by the module number. Second, I
aligned the chapter and section numbers in the online textbook with the
corresponding D2L material. For example, students should work through Section
5.1 in the book--watching videos, reading the text, and attempting the
self-assessment problems--before attempting Activity 5.1. Then they move on
to reading Section 5.2 and completing Activity 5.2, and so forth.

**Translating in-class group activities.** I faced another challenge when
adapting my
classroom learning activities, which students complete in groups, to an
online setting. The asynchronous nature of an online summer course precluded
asking the students to work in groups, so I decided to do my best to mimic
this classroom experience with recorded videos. For each activity, I guided
students through examples, occasionally providing small lecture components,
and then asked students to pause the video and complete additional exercises.
When they restart the video, I would go over my solution and discuss common
mistakes.

The final challenge was implementing a robust online assessment scheme that
would provide a meaningful and authentic assessment of student performance. It has
taking me years to implement a complete solution, which I discuss in the
next section.

## Taking advantage of randomized practice and end-of-module quizzes

{{< figure src="/img/quiz_scheme.png" title="**Figure 3.** After adapting my assessments to an online setting, the final scheme involves material divided into three areas with corresponding review and practice materials.">}}

When adapting assessment materials to the online setting, I had three
motivating goals. First, I wanted to provide students with enough review and
practice to succeed while working alone. Second, I wanted a scheme
that took advantage of the D2L features and allows for the quick turn around
on feedback. Finally, I needed to combat academic dishonesty and get an
authentic assessment of performance.

The final implementation of my assessment scheme consists of splitting
assessment items into three groups: knowledge-based assessments suitable to
multiple-choice questions, questions that gauge written interpretation, and
checking computer skills. I will discuss the reasoning for this split and the
efficacy of my quiz scheme for each of my original goals below.

**Preparation.** To prepare for the end-of-module assessments, students start
by reviewing the questions embedded in the online text, writing
review materials, and JMP how-to videos posted on D2L. Next, students practice
what they have learned using practice quizzes and worksheets. A key feature
of the multiple-choice practice quiz is questions pulled at random
from a large bank of similar problems, allowing students additional
practice through repetition.

**Prompt feedback.** Splitting the multiple-choice and written
quiz questions into two separate assessments allows for a faster turn-around on
grading/feedback. D2L can automatically score the multiple-choice questions
and immediately provide students with their scores, which would not
be possible for quizzes that included short answer questions. I have also
found that I am more efficient in grading three assessments consisting of
similar problems.

**Authentic assessments.** After encountering issues with too much student
collaboration on homework assignments, I moved as much material to D2L quizzes
as possible. Furthermore, multiple-choice and written assessments both pull
questions from a random bank of similar problems, making it harder for
students to collaborate on the quizzes (they likely get different items in a
random order). Finally, I made use of the Respondus Lockdown Browser &
Monitor, which locks down the computer and records activity using the web
camera. These changes make it much harder for students to cheat and
more likely to get an authentic assessment of student learning.

Next, I will discuss a novel project I developed for STAT 310.

## A New Virtual Pilot Study for STAT 310

STAT 310 has recently become a writing-intensive course, so I developed a
project to facilitate written reports along with my colleague Dr. Tisha
Hooks. In this project, students work in groups to design and implement an
experiment on [The Islands](https://islands.smp.uq.edu.au/) (see
**Figure 4**), a virtual environment created by Dr Michael Bulmer from the University of Queensland, 
that provides a (relatively) authentic experience
working with human subjects. Like real-world studies on human subjects,
students must gain consent before working with a resident, and residents have
a habit of dropping out of the study. Students must think about realistic
expectations for measurable change over a short period, i.e., can we expect
the IQ of a resident to change over a short period. Finally, as in real life,
obtaining a simple random sample is nearly impossible, and students need
to find a decent alternative sampling scheme.

{{< figure src="/img/islands.png" title="**Figure 4.** The Islands is a virtual environment that allows students to conduct virtual experiments and studies. The three islands contain residents who can be found in their residence. After gaining consent, students can assign each resident a task as part of a larger study. ">}}


While the first run of the project was promising, one problem that both Dr.
Hooks and I observed was most experiments resulted in non-significant
results. Power is one of the main topics early covered in STAT 310 and is
directly related to this problem: the first round of studies either looked
for differences too minute to detect or did not have enough participants to
see a present difference. When performing expensive real-world studies, it is
customary to complete a small pilot study with several advantages. First, the
pilot study allows the researcher to determine the design feasibility and
find any unforeseen problems. Second—and more importantly—the researcher uses
the resulting data to estimate the sample size needed to have a good chance
of finding a significant difference, i.e., the sample size required for a
specified power level. This critical step makes sure that a researcher
does not waste time and money on an impossible task or waste too much
time and money on unneeded replications on an easy question.

This project provides the perfect opportunity to introduce students to
pilot studies!

When redesigning this project, I reviewed the literature on
pilot studies, and found two excellent articles to share with students.
In particular, Thabane et al. provide several resources,
including a detailed outline for reporting on a pilot study as seen in
**Figure 5**.

In the revised version of the projects, students still started working in a
group to propose a study. After getting some feedback from the instructor,
each group conducted a pilot study and wrote up their results using the
outline provided by Thabane et al. Each group was required to perform and
report on the power analysis for their research question. All of the students
in the class ranked the proposals, with the top 3 receiving a bonus. I
instructed students to pay particular attention to the power analysis and the
amount of work estimated for each prospective study. The whole class then
conducted more extensive research based on the winning design, with the
winning team in charge of managing the class’s work. Finally, each student
wrote a final report on the class’s results.

{{< figure src="/img/pilot_study.png" title=" **Figure 5.** Thabane et al. provide, among other things, a detailed outline for a pilot study; which I found a useful guide for student reports. ">}}

I was pleased with the results of this project. Working with the Islands is a
valuable and fun exercise, evidenced by the student enthusiasm Dr. Hooks and
I witnessed. Furthermore, I hope that running the pilot study first gave the
students real experience thinking about design feasibility and the
importance of a power analysis. Also, first writing about the pilot study and
then writing about the resulting main winning design offered the students a
chance to see two variations on reporting results; with each report
tailored to the goals of the respective design.

{{< figure src="/img/example_project.png" title=" **Figure 6.** One group performed a randomized experiment comparing the effects of petting two types of animals to a baseline control.  As expected, petting a crocodile raises the average heart rate compared to the other two treatment groups.">}}

My colleague Dr. Tisha Hooks used this project in her subsequent STAT 310 courses, and her comments (taken from her [letter of support](/testimonial/hooks_letter_of_support.pdf/))

> STAT 310 recently became a writing intensive course. Todd put a lot of work
> into creating a writing project. Students were required to work in groups
> to choose a research question of interest and then conduct a pilot study to
> investigate that question in a virtual population known as The Islands. He
> found articles that provide > students with the basic knowledge needed to
> design a pilot study, created an assignment description and rubric, and found
> a way to make the project even more fun by encouraging competition amongst
> the students. Fortunately for me, he was willing to share his work so that
> I could use the same assignment in my sections. Overall, the STAT 310
> course is currently in a very good place, and once again, I have Todd to
> thank.
